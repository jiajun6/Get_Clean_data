# CodeBook for this project

## Context

Data was collected by a group of researchers to analyze the possibility of using smartphones with embedded inertial sensors to assess human activity. The experiment was done with 30 subjects carrying the smartphones, who were video-recorded while performing one among six activities(walking, walking upstairs, walking downstairs, sitting, standing, laying). Three-axial linear acceleration ans 3-axial angular velocity were measured with the inertial sensors during activities. The sensor signals were pre-processed (i.e., noise filtering, time window sampling) and 561 features from time and fequency domains were calculated for each activity performed by each subjects. The data set was randomly partitioned into a training set (70% of the subjects) and a testing set (30% of the subjects). The data was made available for further analysis on the UCI Machine Learning Repository. More details on the experiment and the data can be found at the following address:

http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 

## Objectives

The first objective of this project was to first assemble

## Data source

at the following address. 

https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip


## Procedure
- assemble 1
- search for mean() and std()
- reduce

size of matrices
